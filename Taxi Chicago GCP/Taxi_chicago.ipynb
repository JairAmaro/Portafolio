{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Taxi trips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `taxi_id`: Identificador único para el taxi (INTEGER).\n",
    "- `trip_start_timestamp`: Fecha y hora de inicio del viaje, redondeada al intervalo de 15 minutos más cercano (TIMESTAMP).\n",
    "- `trip_end_timestamp`: Fecha y hora de finalización del viaje, redondeada al intervalo de 15 minutos más cercano (TIMESTAMP).\n",
    "- `trip_seconds`: Duración del viaje en segundos (INTEGER).\n",
    "- `trip_miles`: Distancia del viaje en millas (FLOAT).\n",
    "- `pickup_census_tract`: Distrito censal donde comenzó el viaje. Para proteger la privacidad, este dato no se muestra para algunos viajes (INTEGER).\n",
    "- `dropoff_census_tract`: Distrito censal donde terminó el viaje. Para proteger la privacidad, este dato no se muestra para algunos viajes (INTEGER).\n",
    "- `pickup_community_area`: Área comunitaria donde comenzó el viaje (INTEGER).\n",
    "- `dropoff_community_area`: Área comunitaria donde terminó el viaje (INTEGER).\n",
    "- `fare`: Tarifa del viaje (FLOAT).\n",
    "- `tips`: Propina del viaje. Las propinas en efectivo generalmente no se registran (FLOAT).\n",
    "- `tolls`: Peajes del viaje (FLOAT).\n",
    "- `extras`: Cargos adicionales del viaje (FLOAT).\n",
    "- `trip_total`: Costo total del viaje, suma de la tarifa, propinas, peajes y cargos adicionales (FLOAT).\n",
    "- `payment_type`: Tipo de pago para el viaje (STRING).\n",
    "- `company`: Código identificador de la compañía de taxis (INTEGER).\n",
    "- `pickup_latitude`: Código identificador para la latitud del centro del distrito censal de recogida o del área comunitaria si el distrito censal se ha ocultado por motivos de privacidad (INTEGER).\n",
    "- `pickup_longitude`: Código identificador para la longitud del centro del distrito censal de recogida o del área comunitaria si el distrito censal se ha ocultado por motivos de privacidad (INTEGER).\n",
    "- `pickup_location`: Ubicación del centro del distrito censal de recogida o del área comunitaria si el distrito censal se ha ocultado por motivos de privacidad (STRING).\n",
    "- `dropoff_latitude`: Código identificador para la latitud del centro del distrito censal de entrega o del área comunitaria si el distrito censal se ha ocultado por motivos de privacidad (INTEGER).\n",
    "- `dropoff_longitude`: Código identificador para la longitud del centro del distrito censal de entrega o del área comunitaria si el distrito censal se ha ocultado por motivos de privacidad (INTEGER).\n",
    "- `dropoff_location`: Ubicación del centro del distrito censal de entrega o del área comunitaria si el distrito censal se ha ocultado por motivos de privacidad (STRING).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos\n",
    "### Primero limpieramos el catalogo de empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>fare</th>\n",
       "      <th>tips</th>\n",
       "      <th>tolls</th>\n",
       "      <th>extras</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3454.0</td>\n",
       "      <td>2016-5-4 15:00:00</td>\n",
       "      <td>2016-5-4 15:00:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>411.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4432.0</td>\n",
       "      <td>2016-5-24 18:15:00</td>\n",
       "      <td>2016-5-24 18:30:00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>959.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>101.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4076.0</td>\n",
       "      <td>2016-5-4 15:45:00</td>\n",
       "      <td>2016-5-4 15:45:00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Cash</td>\n",
       "      <td>107.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7929.0</td>\n",
       "      <td>2016-5-22 02:00:00</td>\n",
       "      <td>2016-5-22 02:15:00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>101.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>2016-5-12 14:15:00</td>\n",
       "      <td>2016-5-12 14:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.90</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943579</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2016-5-20 16:45:00</td>\n",
       "      <td>2016-5-20 16:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Cash</td>\n",
       "      <td>107.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943580</th>\n",
       "      <td>3948.0</td>\n",
       "      <td>2016-5-10 09:15:00</td>\n",
       "      <td>2016-5-10 09:15:00</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>419.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943581</th>\n",
       "      <td>8696.0</td>\n",
       "      <td>2016-5-3 15:45:00</td>\n",
       "      <td>2016-5-3 16:45:00</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>17.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>57.00</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>43.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943582</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>2016-5-17 09:15:00</td>\n",
       "      <td>2016-5-17 09:30:00</td>\n",
       "      <td>840.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>101.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943583</th>\n",
       "      <td>7777.0</td>\n",
       "      <td>2016-5-7 18:15:00</td>\n",
       "      <td>2016-5-7 18:30:00</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>959.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>754.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1943584 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         taxi_id trip_start_timestamp  trip_end_timestamp  trip_seconds  \\\n",
       "0         3454.0    2016-5-4 15:00:00   2016-5-4 15:00:00         300.0   \n",
       "1         4432.0   2016-5-24 18:15:00  2016-5-24 18:30:00         720.0   \n",
       "2         4076.0    2016-5-4 15:45:00   2016-5-4 15:45:00          60.0   \n",
       "3         7929.0   2016-5-22 02:00:00  2016-5-22 02:15:00        1260.0   \n",
       "4         1985.0   2016-5-12 14:15:00  2016-5-12 14:15:00           0.0   \n",
       "...          ...                  ...                 ...           ...   \n",
       "1943579     32.0   2016-5-20 16:45:00  2016-5-20 16:45:00           0.0   \n",
       "1943580   3948.0   2016-5-10 09:15:00  2016-5-10 09:15:00         660.0   \n",
       "1943581   8696.0    2016-5-3 15:45:00   2016-5-3 16:45:00        2880.0   \n",
       "1943582   1947.0   2016-5-17 09:15:00  2016-5-17 09:30:00         840.0   \n",
       "1943583   7777.0    2016-5-7 18:15:00   2016-5-7 18:30:00         540.0   \n",
       "\n",
       "         trip_miles  pickup_census_tract  dropoff_census_tract  \\\n",
       "0              1.50                  NaN                 676.0   \n",
       "1              0.00                  NaN                 959.0   \n",
       "2              0.00                  NaN                   NaN   \n",
       "3              4.80                  NaN                  16.0   \n",
       "4              0.00                  NaN                   NaN   \n",
       "...             ...                  ...                   ...   \n",
       "1943579        0.00                  NaN                 134.0   \n",
       "1943580        0.55                  NaN                 134.0   \n",
       "1943581       17.90                  NaN                 313.0   \n",
       "1943582        1.50                  NaN                  16.0   \n",
       "1943583        1.10                  NaN                 959.0   \n",
       "\n",
       "         pickup_community_area  dropoff_community_area   fare  tips  tolls  \\\n",
       "0                         28.0                    28.0   7.00   0.0    0.0   \n",
       "1                         32.0                     8.0   8.50   2.0    0.0   \n",
       "2                         28.0                    24.0   4.50   0.0    0.0   \n",
       "3                          6.0                    32.0  17.50   0.0    0.0   \n",
       "4                          NaN                     NaN   7.50   1.4    0.0   \n",
       "...                        ...                     ...    ...   ...    ...   \n",
       "1943579                   24.0                    24.0   3.25   0.0    0.0   \n",
       "1943580                    8.0                    24.0   7.75   2.0    0.0   \n",
       "1943581                    8.0                    76.0  46.00   9.5    0.0   \n",
       "1943582                   32.0                    32.0   9.00   0.0    0.0   \n",
       "1943583                    8.0                     8.0   7.25   0.0    0.0   \n",
       "\n",
       "         extras  trip_total payment_type  company  pickup_latitude  \\\n",
       "0           0.0        7.00         Cash      NaN            411.0   \n",
       "1           0.0       10.50  Credit Card    101.0             18.0   \n",
       "2           0.0        4.50         Cash    107.0            158.0   \n",
       "3           1.0       18.50  Credit Card    101.0            606.0   \n",
       "4           0.0        8.90  Credit Card    119.0              NaN   \n",
       "...         ...         ...          ...      ...              ...   \n",
       "1943579     0.0        3.25         Cash    107.0             45.0   \n",
       "1943580     0.0        9.75  Credit Card      NaN            419.0   \n",
       "1943581     1.5       57.00  Credit Card     43.0            167.0   \n",
       "1943582     0.0        9.00         Cash    101.0            744.0   \n",
       "1943583     1.0        8.25         Cash      NaN            167.0   \n",
       "\n",
       "         pickup_longitude  dropoff_latitude  dropoff_longitude  \n",
       "0                   545.0             779.0               81.0  \n",
       "1                   610.0             167.0              754.0  \n",
       "2                   270.0             199.0              510.0  \n",
       "3                   617.0              18.0              610.0  \n",
       "4                     NaN               NaN                NaN  \n",
       "...                   ...               ...                ...  \n",
       "1943579             163.0              45.0              163.0  \n",
       "1943580             615.0              45.0              163.0  \n",
       "1943581             754.0             225.0                6.0  \n",
       "1943582             605.0              18.0              610.0  \n",
       "1943583             754.0             167.0              754.0  \n",
       "\n",
       "[1943584 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = pd.read_csv(\"C:/Users/oscar/Downloads/Data_chicago/archive/Data/chicago_taxi_trips_2016_05.csv\")\n",
    "prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica la ruta del archivo JSON\n",
    "ruta_archivo = r'C:/Users/oscar/Downloads/Data_chicago/archive/column_remapping.json'\n",
    "# Abre y lee el archivo JSON\n",
    "with open(ruta_archivo) as archivo:\n",
    "    datos = json.load(archivo)\n",
    "\n",
    "    # Convierte los datos a un DataFrame de pandas\n",
    "df = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que en dicho archivo se encuentran los datos de los viajes en taxi en Chicago\n",
    "\n",
    "lo cual haremos merge con nuestra data de los viajes pero \n",
    "* Se debe limpiar los datos (tanto en el archivo josn como en la data)\n",
    "\n",
    "Ya que si vemos hay compañias que estan vacias aun que hay taxi id \n",
    "\n",
    "Despues de analizar los datos hay varios taixs que se perderan que \n",
    "* No tiene ID ni compañia\n",
    "* Solo tiene la clave codificada id pero no podemos descodificar esa info \n",
    "\n",
    "Por parte de esta practica al no tener otra data para recuperar datos posiblmente a esos taxis los separemos en sin compañia etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>25b37d641316c0ca5cb44edf8eaf9f012e2495549f60b7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17031070500</td>\n",
       "      <td>17031070500</td>\n",
       "      <td>41.735123264</td>\n",
       "      <td>-87.655878786</td>\n",
       "      <td>41.735123264</td>\n",
       "      <td>-87.655878786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>adc7f5196ba6908039ab7f7c384e906794213988720341...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17031812802</td>\n",
       "      <td>17031812802</td>\n",
       "      <td>41.779954269</td>\n",
       "      <td>-87.710715958</td>\n",
       "      <td>41.779954269</td>\n",
       "      <td>-87.710715958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>807b5d99114d04269a924c3a1a541b432b8091f9f2e3f7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17031240200</td>\n",
       "      <td>17031240200</td>\n",
       "      <td>41.747534263</td>\n",
       "      <td>-87.67157759</td>\n",
       "      <td>41.747534263</td>\n",
       "      <td>-87.67157759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7c51947e529f0b10e944d3ab51b165bdb1cee520ef7bf8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17031828000</td>\n",
       "      <td>17031828000</td>\n",
       "      <td>41.856333217</td>\n",
       "      <td>-87.617576172</td>\n",
       "      <td>41.856333217</td>\n",
       "      <td>-87.617576172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0e9f2dd7b140154617d473940c36cfb7956c2cd126dfe8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17031760801</td>\n",
       "      <td>17031760801</td>\n",
       "      <td>41.660136051</td>\n",
       "      <td>-87.666536278</td>\n",
       "      <td>41.660136051</td>\n",
       "      <td>-87.666536278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>43aa40841edf3eb3e6112114f39cbd9cae2f45cee24f66...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>ab16f0667f2608e3dc827483fc4541ade5740316bff4ac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>b3947461320274fc1ea81528ba6864a6bb726894fc2109...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>cc2fe5061e6f477a5a502f17b8c73f0b2476dff6025677...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>1aed6522859d97072638fadd1dba2c2fafbfd249561482...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8643 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                taxi_id company  \\\n",
       "120   25b37d641316c0ca5cb44edf8eaf9f012e2495549f60b7...     NaN   \n",
       "121   adc7f5196ba6908039ab7f7c384e906794213988720341...     NaN   \n",
       "122   807b5d99114d04269a924c3a1a541b432b8091f9f2e3f7...     NaN   \n",
       "123   7c51947e529f0b10e944d3ab51b165bdb1cee520ef7bf8...     NaN   \n",
       "124   0e9f2dd7b140154617d473940c36cfb7956c2cd126dfe8...     NaN   \n",
       "...                                                 ...     ...   \n",
       "8758  43aa40841edf3eb3e6112114f39cbd9cae2f45cee24f66...     NaN   \n",
       "8759  ab16f0667f2608e3dc827483fc4541ade5740316bff4ac...     NaN   \n",
       "8760  b3947461320274fc1ea81528ba6864a6bb726894fc2109...     NaN   \n",
       "8761  cc2fe5061e6f477a5a502f17b8c73f0b2476dff6025677...     NaN   \n",
       "8762  1aed6522859d97072638fadd1dba2c2fafbfd249561482...     NaN   \n",
       "\n",
       "     pickup_census_tract dropoff_census_tract pickup_latitude  \\\n",
       "120          17031070500          17031070500    41.735123264   \n",
       "121          17031812802          17031812802    41.779954269   \n",
       "122          17031240200          17031240200    41.747534263   \n",
       "123          17031828000          17031828000    41.856333217   \n",
       "124          17031760801          17031760801    41.660136051   \n",
       "...                  ...                  ...             ...   \n",
       "8758                 NaN                  NaN             NaN   \n",
       "8759                 NaN                  NaN             NaN   \n",
       "8760                 NaN                  NaN             NaN   \n",
       "8761                 NaN                  NaN             NaN   \n",
       "8762                 NaN                  NaN             NaN   \n",
       "\n",
       "     pickup_longitude dropoff_latitude dropoff_longitude  \n",
       "120     -87.655878786     41.735123264     -87.655878786  \n",
       "121     -87.710715958     41.779954269     -87.710715958  \n",
       "122      -87.67157759     41.747534263      -87.67157759  \n",
       "123     -87.617576172     41.856333217     -87.617576172  \n",
       "124     -87.666536278     41.660136051     -87.666536278  \n",
       "...               ...              ...               ...  \n",
       "8758              NaN              NaN               NaN  \n",
       "8759              NaN              NaN               NaN  \n",
       "8760              NaN              NaN               NaN  \n",
       "8761              NaN              NaN               NaN  \n",
       "8762              NaN              NaN               NaN  \n",
       "\n",
       "[8643 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan = df[pd.isna(df['company'])]\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_14220\\2562288771.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['company'] = df['company'].str.replace(regex_pattern, '', regex=True).str.strip()\n"
     ]
    }
   ],
   "source": [
    "def drop_terminology(df):\n",
    "    # Definir las palabras a eliminar\n",
    "    palabras_a_eliminar = ['Cab', 'Co', 'Inc', 'Corp', 'inc', 'llc', 'LLC', 'Inc.', 'Corp.', 'Group', 'Group,']\n",
    "    df['company'] = df['company'].str.rstrip('.')\n",
    "    df = df.dropna()\n",
    "    # Crear una expresión regular que coincida con cualquier palabra en la lista\n",
    "    regex_pattern = r'\\b(?:' + '|'.join(palabras_a_eliminar) + r')\\b'\n",
    "    # Usar str.replace con la expresión regular para eliminar las palabras\n",
    "    df['company'] = df['company'].str.replace(regex_pattern, '', regex=True).str.strip()\n",
    "    return df\n",
    "df = drop_terminology(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_map(df):\n",
    "    # Eliminar espacios en blanco alrededor de todas las celdas de tipo cadena\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    # Eliminar filas con valores nulos ya que no se pueden mapear la compañía\n",
    "    df = df.dropna()\n",
    "    # Usar una expresión regular para dividir la columna 'company' de los '-' ya que algunos estan con y sin espacio\n",
    "    split_columns = df['company'].str.split(r'\\s*-\\s*|\\s*-\\s*', expand=False)\n",
    "    # Crear nuevas columnas 'ID_Taxi' y 'company'\n",
    "    df['ID_Taxi'] = split_columns.apply(lambda x: x[0].strip() if len(x) > 1 else None)\n",
    "    df['company_clean'] = split_columns.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "\n",
    "    # Para saber como se hizo los strip a company no la alteraremo\n",
    "    #df['company'] = split_columns.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "\n",
    "    # eliminar los ID de 5 digitos normalmente son 4 pero re por que hay valores alfa numerioc sy no queremos eliminarlos compañias que tengan 5 digitos como nombre \n",
    "    df['company_clean'] = df['company_clean'].apply(lambda x: re.sub(r'\\b\\d{5} ', '', x))\n",
    "\n",
    "    # Hay compañias que solo tienen el ID bien, solo pondremo sin nombre y su ID ya que no se puede identificar\n",
    "    df['company_clean'] = df.apply(lambda row: f\"Sin nombre {row['ID_Taxi']}\" if re.fullmatch(r'\\d+', row['company_clean']) else row['company_clean'], axis=1)\n",
    "    \n",
    "    return df\n",
    "df = clean_df_map(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>ID_Taxi</th>\n",
       "      <th>company_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e8872981b0207dc88bc7fc2778d1bf870967eb83ee03ac...</td>\n",
       "      <td>Chicago Medallion Management</td>\n",
       "      <td>17031831600</td>\n",
       "      <td>17031831600</td>\n",
       "      <td>42.005608023</td>\n",
       "      <td>-87.672538401</td>\n",
       "      <td>42.005608023</td>\n",
       "      <td>-87.672538401</td>\n",
       "      <td>None</td>\n",
       "      <td>Chicago Medallion Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d904764719c56cfb36906cb74c313be2fe666cf5b071da...</td>\n",
       "      <td>Blue Ribbon Taxi Association</td>\n",
       "      <td>17031580700</td>\n",
       "      <td>17031580700</td>\n",
       "      <td>41.921084583</td>\n",
       "      <td>-87.708416729</td>\n",
       "      <td>41.921084583</td>\n",
       "      <td>-87.708416729</td>\n",
       "      <td>None</td>\n",
       "      <td>Blue Ribbon Taxi Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3fa040c240f0b86be0d9b46ce482b0e761904f5872f616...</td>\n",
       "      <td>KOAM Taxi Association</td>\n",
       "      <td>17031827902</td>\n",
       "      <td>17031827902</td>\n",
       "      <td>41.697269192</td>\n",
       "      <td>-87.731711853</td>\n",
       "      <td>41.697269192</td>\n",
       "      <td>-87.731711853</td>\n",
       "      <td>None</td>\n",
       "      <td>KOAM Taxi Association</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              taxi_id  \\\n",
       "3   e8872981b0207dc88bc7fc2778d1bf870967eb83ee03ac...   \n",
       "8   d904764719c56cfb36906cb74c313be2fe666cf5b071da...   \n",
       "10  3fa040c240f0b86be0d9b46ce482b0e761904f5872f616...   \n",
       "\n",
       "                         company pickup_census_tract dropoff_census_tract  \\\n",
       "3   Chicago Medallion Management         17031831600          17031831600   \n",
       "8   Blue Ribbon Taxi Association         17031580700          17031580700   \n",
       "10         KOAM Taxi Association         17031827902          17031827902   \n",
       "\n",
       "   pickup_latitude pickup_longitude dropoff_latitude dropoff_longitude  \\\n",
       "3     42.005608023    -87.672538401     42.005608023     -87.672538401   \n",
       "8     41.921084583    -87.708416729     41.921084583     -87.708416729   \n",
       "10    41.697269192    -87.731711853     41.697269192     -87.731711853   \n",
       "\n",
       "   ID_Taxi                 company_clean  \n",
       "3     None  Chicago Medallion Management  \n",
       "8     None  Blue Ribbon Taxi Association  \n",
       "10    None         KOAM Taxi Association  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_id_nan = df[pd.isna(df['ID_Taxi'])]\n",
    "taxi_id_nan.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores en 'company_clean'\n",
    "df['company_clean'] = df['company_clean'].replace({'CD': 'CID', 'Payment Only': 'T.A.S. - Payment Only'})\n",
    "\n",
    "# Reemplazar 'T.A.S.' por '0' en 'ID_Taxi' y llenar valores vacíos con '0'\n",
    "df['ID_Taxi'] = df['ID_Taxi'].replace('T.A.S.', '0')\n",
    "df['ID_Taxi'].fillna('0', inplace=True)\n",
    "\n",
    "# Crear una máscara para los valores '0' en 'ID_Taxi'\n",
    "mask_zeros = df['ID_Taxi'] == '0'\n",
    "\n",
    "# Eliminar duplicados en 'ID_Taxi', manteniendo solo la primera ocurrencia\n",
    "df_no_zeros = df[~mask_zeros].drop_duplicates(subset='ID_Taxi', keep='first')\n",
    "\n",
    "# Concatenar el DataFrame sin los '0' con los '0' al final\n",
    "df = pd.concat([df_no_zeros, df[mask_zeros]], ignore_index=True)\n",
    "\n",
    "# Ordenar por 'company_clean' de forma alfabética\n",
    "df.sort_values(by='company_clean', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora limpieramos la data donde concatenaremos el catalogo de empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_taxis(prueba):\n",
    "    # Rellenar 'taxi_id' con el valor de 'company' cuando 'taxi_id' es NaN, nulo, espacio en blanco o vacío\n",
    "    prueba['taxi_id'] = prueba.apply(lambda row: row['company'] if pd.isna(row['taxi_id']) or (isinstance(row['taxi_id'], str) and row['taxi_id'].strip() == '') else row['taxi_id'], axis=1)\n",
    "\n",
    "    return prueba\n",
    "\n",
    "def types_for_columns(prueba, taxi_id, company):\n",
    "    prueba[taxi_id] = prueba[taxi_id].astype(int)\n",
    "    prueba[company] = prueba[company].astype(str)\n",
    "    \n",
    "    return prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_format(prueba):\n",
    "    # Supongamos que tu DataFrame se llama 'prueba' y la columna de fecha se llama 'trip_start_timestamp'\n",
    "    prueba['trip_start_timestamp'] = pd.to_datetime(prueba['trip_start_timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "    # Repetimos el proceso para la columna 'trip_end_timestamp'\n",
    "    prueba['trip_end_timestamp'] = pd.to_datetime(prueba['trip_end_timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "    return prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_process_data(prueba, df):\n",
    "    prueba = clean_data_taxis(prueba)\n",
    "    prueba = types_for_columns(prueba, 'taxi_id', 'company')\n",
    "    prueba = Time_format(prueba)\n",
    "    prueba = prueba.drop(columns=['company'])\n",
    "    df = types_for_columns(df, 'ID_Taxi', 'company_clean')\n",
    "\n",
    "    df = df[['pickup_census_tract', 'dropoff_census_tract', 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'ID_Taxi', 'company_clean']]\n",
    "    df.columns = ['pickup_tract', 'dropoff_tract', 'pickup_lat', 'pickup_long', 'dropoff_lat', 'dropoff_long', 'ID_Taxi', 'company_name']\n",
    "\n",
    "    # Merge entre los DataFrames\n",
    "    df_process = pd.merge(prueba, df, left_on='taxi_id', right_on='ID_Taxi', how='inner')\n",
    "    # Estos errores son básicamente los taxis que no se encuentran en el archivo de mapeo donde está su ID por lo cual sería mejor con cliente arreglarlo que simplemente eliminarlo pero no los mapearemos\n",
    "    error_id_company = prueba[~prueba['taxi_id'].isin(df_process['taxi_id'])]\n",
    "    df_process = df_process.drop('pickup_census_tract', axis=1)\n",
    "    df_process = df_process.fillna(0.00)\n",
    "\n",
    "    return df_process, error_id_company\n",
    "\n",
    "# Uso de la función\n",
    "# df_process, error_id_company = cleaning_process_data(prueba, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/oscar/Downloads/Data_chicago/archive/Data/\"\n",
    "\n",
    "# Listas para almacenar los resultados de cada archivo\n",
    "df_list = []\n",
    "error_df_list = []\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Cargar el archivo CSV\n",
    "        prueba = pd.read_csv(file_path)\n",
    "        # Aplicar cleaning_process_data a cada archivo\n",
    "        df_process, error_id_company = cleaning_process_data(prueba, df)\n",
    "        # Almacenar los resultados en las listas\n",
    "        df_list.append(df_process)\n",
    "        error_df_list.append(error_id_company)\n",
    "\n",
    "# Concatenar todos los resultados para obtener el DataFrame final\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "error_df = pd.concat(error_df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19740176"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"C:/Users/oscar/Downloads/Data_chicago/archive/df_final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones\n",
    " * Hay 19740176 datos en error, los cuales a nivel cliente lo ideal es plantear una solucion para recuperar esos datos asi tener una mejor toma de decisiones\n",
    " * No se toman por que no se podria unir para obtener cordenadas de viaje, es mucho mejor que un cliente llene esos ID y evitar sesgos\n",
    " * Se podria tener un catalogo de ID omologado para que se pueda recuperar la informacion de los viajes inclusive a futuro y que todo sea automatizado \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos una tabla analitica de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizar la información a nivel compañía \n",
    "- (a) Nombre de la compañía\n",
    "- (b) Número de Taxis pertenecientes a la compañía\n",
    "- (c) Número promedio de viajes por taxi\n",
    "- (d) Tarifa promedio por viaje\n",
    "- (e) Propina promedio por viaje\n",
    "- (f) Costo promedio de las herramientas utilizadas\n",
    "- (g) Extras promedio\n",
    "- (h) Duración promedio de los viajes\n",
    "- (i) Duración total de los viajes\n",
    "- (j) Distancia promedio por viaje\n",
    "- (k) Distancia total recorrida por sus taxis\n",
    "- (l) Distancia máxima recorrida en un viaje\n",
    "- (m) Distancia mínima recorrida en un viaje\n",
    "- (n) Tiempo máximo recorrido en un viaje\n",
    "- (o) Tiempo mínimo recorrido en un viaje\n",
    "- (p) Tipo de pago con mayor recurrencia\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
